
<div align="center">
  <img src="https://github.com/TheItCrOw/R.O.B.E.R.T./assets/49918134/a19fa9f1-d77e-49b9-912a-28012ef9f435"/>
  <hr/>
  <h1>An open-source instruction-following large language chatting model that self-instructs itself into your specific domain.</h1>
</div

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

This is the repository for R.O.B.E.R.T., a chatting assistant that self-instructs itself into a specificially provided context by generating the needed datasets itself and then finetuning the LLaMa model on these datasets.
This project wouldn't be possible without:

- [Lighting-AI/lit-llama](https://github.com/Lightning-AI/lit-llama)
- [nomic-ai/gpt4all](https://github.com/nomic-ai/gpt4all)
- [openai/chatgpt](https://openai.com/blog/chatgpt)
- [MetaAI/LLaMa](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)



